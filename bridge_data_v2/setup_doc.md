## ğŸš€ Quick Overview

æœ¬é¡¹ç›®ä½¿ç”¨ JAX + Flax è¿›è¡Œè®­ç»ƒï¼Œæ•°æ®ä»¥ BridgeData TFRecord ç»„ç»‡ã€‚è¿‘æœŸæˆ‘ä»¬ä¿®å¤äº†è‹¥å¹²ä¾èµ–/è¿è¡Œæ—¶é—®é¢˜ï¼Œå¹¶å®Œå–„äº†å¤šå®éªŒå¯åŠ¨æµç¨‹ã€‚ä»¥ä¸‹æ–‡æ¡£æ±‡æ€»ç¯å¢ƒæ­å»ºã€æ•°æ®å¤„ç†ä¸è®­ç»ƒæ­¥éª¤ï¼Œå¹¶æ ‡æ³¨å…³é”®å˜æ›´ä¸æ’éšœå»ºè®®ã€‚

---

## ğŸ”§ ç¯å¢ƒå‡†å¤‡ï¼ˆJAX/TF/æ˜¾å¡ï¼‰

å»ºè®®åœ¨ç‹¬ç«‹è™šæ‹Ÿç¯å¢ƒä¸­å®‰è£…ä¾èµ–ã€‚ä»¥ä¸‹ç‰ˆæœ¬å·²éªŒè¯äº’ç›¸å…¼å®¹ï¼š

```bash
# 1) å®‰è£… JAX (CUDA 12 pip wheels)
pip install --upgrade "jax[cuda12_pip]==0.4.13" \
  -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html

# 2) ç§‘å­¦è®¡ç®—åŸºç¡€
pip install "scipy>=1.10,<1.12"

# 3) è§£å†³ tensorstore â†” ml-dtypes å…¼å®¹é—®é¢˜ï¼ˆéœ€è¦ float8_e3m4ï¼‰
pip install -U "ml-dtypes>=0.5.0"   # æˆ‘ä»¬ä½¿ç”¨åˆ°çš„æ˜¯ 0.5.3

# 4) è§£å†³ distrax/TFP ä¸ TF 2.15 çš„ç­¾åå†²çª
pip install -U "tensorflow-probability==0.22.1"

# 5) æä¾›ä¸ jaxlib å¯¹é½çš„ NVIDIA è¿è¡Œæ—¶åº“ï¼ˆCUDA12 ç³»ï¼‰
#    è¿™äº›åº“æ¥è‡ª pipï¼Œæ— éœ€ç³»ç»Ÿ CUDA Toolkit å³å¯è¿è¡Œ
pip install -U \
  "nvidia-cuda-runtime-cu12==12.2.*" \
  "nvidia-cublas-cu12==12.2.*" \
  "nvidia-cudnn-cu12==8.9.*" \
  "nvidia-cusolver-cu12==11.5.*" \
  "nvidia-cusparse-cu12==12.1.*" \
  "nvidia-nvjitlink-cu12==12.9.*"
```

æç¤ºï¼šæˆ‘ä»¬é»˜è®¤è®© TensorFlow ä½¿ç”¨ CPUï¼ŒJAX ä½¿ç”¨ GPUï¼Œä»¥é¿å… TF/GPU ä¸ JAX/CUDA åº“çš„å†²çªï¼ˆè®­ç»ƒè„šæœ¬å·²å†…ç½®è®¾ç½®ï¼‰ã€‚

---

## ğŸ§© ä»£ç æ”¹åŠ¨ä¸é…ç½®å˜æ›´

æœ¬æ¬¡ä¸ºç¨³å®šè®­ç»ƒï¼Œåšäº†ä»¥ä¸‹å…³é”®æ”¹åŠ¨ï¼š

- æ–‡ä»¶ `jaxrl_m/common/encoding.py`
  - ä¿®å¤è§‚æµ‹ç¼–ç ä¸æœ¬ä½“æ„Ÿè§‰ï¼ˆproprioï¼‰æ‹¼æ¥æ—¶çš„ç»´åº¦ä¸ä¸€è‡´é—®é¢˜ã€‚
  - å½“ `observations["proprio"]` å½¢å¦‚ `(B, 1, P)` æˆ– `(B, T, P)` æ—¶ï¼Œä¼šè‡ªåŠ¨å±•å¹³æˆ `(B, T*P)` åå†ä¸ç¼–ç  `(B, F)` æ‹¼æ¥ï¼Œä¿®å¤é”™è¯¯ï¼š
    - Cannot concatenate arrays with different numbers of dimensions: got (B, F), (B, 1, P)

- æ–‡ä»¶ `experiments/multi_train.py`
  - æ–°å¢è‡ªåŠ¨å‘ç°å¹¶æ³¨å…¥ pip æä¾›çš„ NVIDIA è¿è¡Œåº“ç›®å½•åˆ° `LD_LIBRARY_PATH`ï¼ˆcuDNN/cuBLAS/NVJitLink ç­‰ï¼‰ï¼Œé¿å…ç³»ç»Ÿ CUDA Toolkit ç‰ˆæœ¬ä¸åŒ¹é…ã€‚
  - æ”¯æŒä» YAML ä¼ å…¥ `XLA_FLAGS`ï¼ˆä¿®å¤æŸäº›æœºå™¨çš„ nvlink æŠ¥é”™ï¼‰ï¼Œ`JAX_PLATFORM_NAME`ï¼ˆå¯å¼ºåˆ¶ CPU/GPUï¼‰ã€‚

- æ–‡ä»¶ `experiments/configs/multi_train.yaml`
  - æ–°å¢å…¨å±€å­—æ®µï¼š
    - `xla_flags: "--xla_gpu_force_compilation_parallelism=1"`ï¼ˆâš ï¸ ç”¨äºè§„é¿ nvlink linking API å¹¶è¡Œ bugï¼‰ã€‚
    - `use_pip_cuda_libs: true`ï¼ˆä¼˜å…ˆä½¿ç”¨ pip æä¾›çš„ CUDA è¿è¡Œåº“ï¼‰ã€‚
    - ä¿ç•™ `cuda_visible_devices: "0"`ï¼Œé»˜è®¤ä½¿ç”¨å•å¡ï¼Œé¿å… batch size æ•´é™¤é—®é¢˜ã€‚

---

## ğŸ§± æ•°æ®å¤„ç†ï¼ˆTASL/LIRA ä¸¤å¥—è·¯å¾„ï¼‰

TASL æœºå™¨ç¤ºä¾‹ï¼š

```bash
python data_processing/bridgedata_raw_to_numpy.py \
  --input_path /data3/vla-reasoning/dataset/bdv2 \
  --output_path /data3/vla-reasoning/dataset/bdv2_numpy \
  --depth 2 --num_workers 8 --train_proportion 0.9 --im_size 256

python data_processing/bridgedata_numpy_to_tfrecord.py \
  --input_path /data3/vla-reasoning/dataset/bdv2_numpy \
  --output_path /data3/vla-reasoning/dataset/bdv2_tfrecord \
  --depth 2 --num_workers 1 --im_size 256
```

LIRA æœºå™¨ç¤ºä¾‹ï¼š

```bash
python data_processing/bridgedata_raw_to_numpy.py \
  --input_path /scr/litian/dataset/bdv2 \
  --output_path /scr/litian/dataset/bdv2_numpy \
  --depth 2 --num_workers 8 --train_proportion 0.99 --im_size 256

python data_processing/bridgedata_numpy_to_tfrecord.py \
  --input_path /scr/litian/dataset/bdv2_numpy \
  --output_path /scr/litian/dataset/bdv2_tfrecord \
  --depth 2 --num_workers 1
```

---

## ğŸ§ª è®­ç»ƒï¼ˆå•/å¤šå®éªŒï¼‰

å•æ¬¡å¤šå®éªŒå¯åŠ¨ï¼š

```bash
python experiments/multi_train.py \
  --config /home/litian/proj/GABRIL-CARLA/bridge_data_v2/experiments/configs/multi_train.yaml
```

åå°è¿è¡Œï¼ˆnohupï¼‰ï¼š

```bash
nohup python experiments/multi_train.py \
  --config /home/litian/proj/GABRIL-CARLA/bridge_data_v2/experiments/configs/multi_train.yaml \
  > log.txt 2>&1 &
```

YAML å…³é”®å­—æ®µè§£é‡Šï¼ˆ`experiments/configs/multi_train.yaml` â†’ `global:`ï¼‰ï¼š

- `data_root` / `save_dir`ï¼šæ•°æ®ä¸ä¿å­˜è·¯å¾„ã€‚
- `train_batch_size` / `val_batch_size`ï¼šè®­ç»ƒ/éªŒè¯ batchï¼›æ³¨æ„éœ€æ»¡è¶³â€œèƒ½æ•´é™¤è®¾å¤‡æ•°â€çš„çº¦æŸã€‚
- `cuda_visible_devices`ï¼šé»˜è®¤ `"0"` ä¿æŒå•å¡ï¼Œé¿å… batch æ•´é™¤é—®é¢˜ã€‚å¤šå¡æ—¶è¯·æŠŠ `train_batch_size` è®¾ä¸ºè®¾å¤‡æ•°çš„å€æ•°ã€‚
- `xla_flags`ï¼šé»˜è®¤ `--xla_gpu_force_compilation_parallelism=1` ä»¥ç¨³å®š CUDA linkingã€‚
- `use_pip_cuda_libs`ï¼šé»˜è®¤å¼€å¯ï¼›è‡ªåŠ¨æŠŠ pip çš„ CUDA è¿è¡Œåº“æ³¨å…¥ `LD_LIBRARY_PATH`ã€‚
- å¯é€‰ `jax_platform_name`ï¼šå¼ºåˆ¶ `cpu` æˆ– `gpu`ï¼ˆéœ€æ—¶å¯ä»¥ä¸´æ—¶åˆ‡åˆ° CPU éªŒè¯ï¼‰ã€‚

---

## ğŸ©º å¸¸è§é—®é¢˜æ’æŸ¥ï¼ˆTroubleshootingï¼‰

- ImportError: tensorstore åˆå§‹åŒ–å¤±è´¥ï¼Œæˆ– `ml_dtypes` æç¤ºç¼ºå°‘ `float8_e3m4`
  - è¿è¡Œï¼š`pip install -U ml-dtypes>=0.5.0`

- TFP æŠ¥ `Arg specs do not match`ï¼ˆä¸ TF çš„ `tf.ones_like` ç­¾åå†²çªï¼‰
  - è¿è¡Œï¼š`pip install -U tensorflow-probability==0.22.1`ï¼ˆåŒ¹é… TF 2.15ï¼‰

- `DNN library initialization failed`ï¼ˆcuDNN åˆå§‹åŒ–å¤±è´¥ï¼‰
  - ç¡®ä¿å®‰è£…å¹¶æ³¨å…¥ pip çš„ CUDA è¿è¡Œåº“ï¼ˆè§ä¸Šæ–‡ç¬¬ 5 æ­¥ï¼‰ã€‚
  - è‹¥ä»æœ‰é—®é¢˜ï¼Œä¸´æ—¶åˆ‡ CPUï¼šåœ¨ YAML é‡Œè®¾ç½® `jax_platform_name: "cpu"` æˆ– `cuda_visible_devices: ""`ã€‚

- `nvlink fatal : Input file ... newer than toolkit (129 vs 124)`
  - å®‰è£… `nvidia-nvjitlink-cu12==12.9.*` å¹¶è®¾ç½® `xla_flags: --xla_gpu_force_compilation_parallelism=1`ã€‚

- `Cannot concatenate arrays ... (B, F) vs (B, 1, P)`
  - å·²åœ¨ `jaxrl_m/common/encoding.py` ç»Ÿä¸€å±•å¹³ proprioï¼›è¯·æ›´æ–°ä»£ç åé‡è¯•ã€‚

---

## ğŸ§­ å°è´´å£«

- æˆ‘ä»¬åœ¨è®­ç»ƒè„šæœ¬é‡Œé»˜è®¤è®© TensorFlow åªç”¨ CPUï¼Œä»¥é¿å…ä¸ JAX/CUDA å†²çªï¼›JAX ä»ä½¿ç”¨ GPUã€‚
- å¤šå¡è®­ç»ƒæ—¶è¯·ç¡®è®¤ `train_batch_size % local_device_count == 0`ã€‚
- Weights & Biases ä¼šè‡ªåŠ¨åˆå§‹åŒ–å¹¶è®°å½•è¿è¡Œï¼›å¦‚æœéœ€è¦ç¦»çº¿å¯ç”¨ `wandb offline`ã€‚

ç¥è®­ç»ƒé¡ºåˆ©ï¼ğŸ¯
